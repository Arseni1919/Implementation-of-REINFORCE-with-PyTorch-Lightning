{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IMPORTS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from REINFORCE import Model, RLDataset, REINFORCELightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = 'CartPole-v1'\n",
    "env = gym.make(env_id)\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "net = Model(obs_size, n_actions)\n",
    "dataset = RLDataset(net, env)\n",
    "dataloader = DataLoader(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of batch = 0\n",
      "len of sample in batch = 21\n",
      "-------------------\n",
      "0 [tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64), tensor([1.], dtype=torch.float64)]\n",
      "-------------------\n",
      "0 [tensor([-3.9399], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([-4.0087], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([-4.2126], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([-4.4649], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64), tensor([nan], dtype=torch.float64)]\n",
      "-------------------\n",
      "0 [tensor([[-0.0204,  0.0195,  0.0457, -0.0380]], dtype=torch.float64), tensor([[-0.0200,  0.2139,  0.0449, -0.3159]], dtype=torch.float64), tensor([[-0.0157,  0.0182,  0.0386, -0.0094]], dtype=torch.float64), tensor([[-0.0154,  0.2127,  0.0384, -0.2897]], dtype=torch.float64), tensor([[-0.0111,  0.0171,  0.0326,  0.0149]], dtype=torch.float64), tensor([[-0.0108, -0.1785,  0.0329,  0.3177]], dtype=torch.float64), tensor([[-0.0143, -0.3741,  0.0393,  0.6206]], dtype=torch.float64), tensor([[-0.0218, -0.1795,  0.0517,  0.3405]], dtype=torch.float64), tensor([[-0.0254,  0.0148,  0.0585,  0.0646]], dtype=torch.float64), tensor([[-0.0251,  0.2090,  0.0598, -0.2091]], dtype=torch.float64), tensor([[-0.0209,  0.0131,  0.0556,  0.1019]], dtype=torch.float64), tensor([[-0.0207, -0.1828,  0.0577,  0.4116]], dtype=torch.float64), tensor([[-0.0243,  0.0115,  0.0659,  0.1376]], dtype=torch.float64), tensor([[-0.0241,  0.2056,  0.0686, -0.1336]], dtype=torch.float64), tensor([[-0.0200,  0.0096,  0.0660,  0.1799]], dtype=torch.float64), tensor([[-0.0198, -0.1864,  0.0696,  0.4927]], dtype=torch.float64), tensor([[-0.0235, -0.3824,  0.0794,  0.8064]], dtype=torch.float64), tensor([[-0.0312, -0.5786,  0.0956,  1.1230]], dtype=torch.float64), tensor([[-0.0427, -0.7748,  0.1180,  1.4441]], dtype=torch.float64), tensor([[-0.0582, -0.9712,  0.1469,  1.7712]], dtype=torch.float64), tensor([[-0.0777, -1.1676,  0.1823,  2.1057]], dtype=torch.float64)]\n",
      "-------------------\n",
      "0 [tensor([1]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([1]), tensor([1]), tensor([0]), tensor([0]), tensor([1]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    # print(i_batch, sample_batched['image'].size(),\n",
    "    #       sample_batched['landmarks'].size())\n",
    "    print(f'num of batch = {i_batch}')\n",
    "    print(f'len of sample in batch = {len(sample_batched[0])}')\n",
    "    print('-------------------')\n",
    "    print(i_batch, sample_batched[0])\n",
    "    print('-------------------')\n",
    "    print(i_batch, sample_batched[1])\n",
    "    print('-------------------')\n",
    "    print(i_batch, sample_batched[2])\n",
    "    print('-------------------')\n",
    "    print(i_batch, sample_batched[3])\n",
    "    print('-------------------')\n",
    "#     print(i_batch, sample_batched[4])\n",
    "#     print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REINFORCELightning(\n",
       "  (net): Model(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=8, out_features=2, bias=True)\n",
       "      (5): Softmax(dim=0)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = REINFORCELightning(env_id)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "[1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 1 0]\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0])\n",
      "---\n",
      "tensor([[0.0415, 0.0431],\n",
      "        [0.0409, 0.0427],\n",
      "        [0.0415, 0.0431],\n",
      "        [0.0425, 0.0436],\n",
      "        [0.0414, 0.0430],\n",
      "        [0.0424, 0.0436],\n",
      "        [0.0433, 0.0438],\n",
      "        [0.0445, 0.0437],\n",
      "        [0.0433, 0.0438],\n",
      "        [0.0423, 0.0435],\n",
      "        [0.0433, 0.0438],\n",
      "        [0.0446, 0.0437],\n",
      "        [0.0434, 0.0437],\n",
      "        [0.0447, 0.0436],\n",
      "        [0.0435, 0.0437],\n",
      "        [0.0449, 0.0435],\n",
      "        [0.0438, 0.0436],\n",
      "        [0.0427, 0.0436],\n",
      "        [0.0441, 0.0435],\n",
      "        [0.0456, 0.0434],\n",
      "        [0.0445, 0.0434],\n",
      "        [0.0461, 0.0433],\n",
      "        [0.0450, 0.0433]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)\n",
      "---\n",
      "tensor([0.0431, 0.0409, 0.0415, 0.0436, 0.0414, 0.0424, 0.0433, 0.0437, 0.0438,\n",
      "        0.0423, 0.0433, 0.0437, 0.0434, 0.0436, 0.0435, 0.0435, 0.0436, 0.0427,\n",
      "        0.0441, 0.0434, 0.0445, 0.0433, 0.0450], dtype=torch.float64,\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "---\n",
      "tensor([-3.1443, -3.1967, -3.1819, -3.1332, -3.1835, -3.1601, -3.1388, -3.1300,\n",
      "        -3.1284, -3.1629, -3.1400, -3.1315, -3.1379, -3.1327, -3.1339, -3.1341,\n",
      "        -3.1329, -3.1525, -3.1207, -3.1372, -3.1116, -3.1394, -3.1002],\n",
      "       dtype=torch.float64, grad_fn=<LogBackward>)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "#     for state in sample_batched[2]:\n",
    "#         out = model(state)\n",
    "#         print(out)\n",
    "    print(len(sample_batched[2]))\n",
    "    state = torch.cat(sample_batched[2])\n",
    "    actions = torch.cat(sample_batched[3])\n",
    "    print(actions.numpy())\n",
    "#     print(state)\n",
    "    print(actions)\n",
    "    print('---')\n",
    "    out = model(state)\n",
    "    print(out)\n",
    "    print('---')\n",
    "#     print(out.squeeze(0))\n",
    "#     probs = out[list(actions.numpy())]\n",
    "    probs = out.gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "    print(probs)\n",
    "    print('---')\n",
    "    log_probs = torch.log(probs)\n",
    "    print(log_probs)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
